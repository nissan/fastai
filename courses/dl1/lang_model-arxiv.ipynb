{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: This notebook will only work with fastai-0.7.x. Do not try to run any fastai-1.x code from this path in the repository because it will load fastai-0.7.x**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
||||||| merged common ancestors
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.model import fit\n",
    "from fastai.dataset import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "bs,bptt = 64,70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, time\n",
    "# feedparser isn't a fastai dependency so you may need to install it.\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class GetArXiv(object):\n",
    "    def __init__(self, pickle_path, categories=list()):\n",
    "        \"\"\"\n",
    "        :param pickle_path (str): path to pickle data file to save/load\n",
    "        :param pickle_name (str): file name to save pickle to path\n",
    "        :param categories (list): arXiv categories to query\n",
    "        \"\"\"\n",
    "        if os.path.isdir(pickle_path):\n",
    "            pickle_path = f\"{pickle_path}{'' if pickle_path[-1] == '/' else '/'}all_arxiv.pkl\"\n",
    "        if len(categories) < 1:\n",
    "            categories = ['cs*', 'cond-mat.dis-nn', 'q-bio.NC', 'stat.CO', 'stat.ML']\n",
    "        # categories += ['cs.CV', 'cs.AI', 'cs.LG', 'cs.CL']\n",
    "\n",
    "        self.categories = categories\n",
    "        self.pickle_path = pickle_path\n",
    "        self.base_url = 'http://export.arxiv.org/api/query'\n",
    "\n",
    "    @staticmethod\n",
    "    def build_qs(categories):\n",
    "        \"\"\"Build query string from categories\"\"\"\n",
    "        return '+OR+'.join(['cat:'+c for c in categories])\n",
    "\n",
    "    @staticmethod\n",
    "    def get_entry_dict(entry):\n",
    "        \"\"\"Return a dictionary with the items we want from a feedparser entry\"\"\"\n",
    "        try:\n",
    "            return dict(title=entry['title'], authors=[a['name'] for a in entry['authors']],\n",
    "                        published=pd.Timestamp(entry['published']), summary=entry['summary'],\n",
    "                        link=entry['link'], category=entry['category'])\n",
    "        except KeyError:\n",
    "            print('Missing keys in row: {}'.format(entry))\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def strip_version(link):\n",
    "        \"\"\"Strip version number from arXiv paper link\"\"\"\n",
    "        return link[:-2]\n",
    "\n",
    "    def fetch_updated_data(self, max_retry=5, pg_offset=0, pg_size=1000, wait_time=15):\n",
    "        \"\"\"\n",
    "        Get new papers from arXiv server\n",
    "        :param max_retry: max number of time to retry request\n",
    "        :param pg_offset: number of pages to offset\n",
    "        :param pg_size: num abstracts to fetch per request\n",
    "        :param wait_time: num seconds to wait between requests\n",
    "        \"\"\"\n",
    "        i, retry = pg_offset, 0\n",
    "        df = pd.DataFrame()\n",
    "        past_links = []\n",
    "        if os.path.isfile(self.pickle_path):\n",
    "            df = pd.read_pickle(self.pickle_path)\n",
    "            df.reset_index()\n",
    "        if len(df) > 0: past_links = df.link.apply(self.strip_version)\n",
    "\n",
    "        while True:\n",
    "            params = dict(search_query=self.build_qs(self.categories),\n",
    "                          sortBy='submittedDate', start=pg_size*i, max_results=pg_size)\n",
    "            response = requests.get(self.base_url, params='&'.join([f'{k}={v}' for k, v in params.items()]))\n",
    "            entries = feedparser.parse(response.text).entries\n",
    "            if len(entries) < 1:\n",
    "                if retry < max_retry:\n",
    "                    retry += 1\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                break\n",
    "\n",
    "            results_df = pd.DataFrame([self.get_entry_dict(e) for e in entries])\n",
    "            max_date = results_df.published.max().date()\n",
    "            new_links = ~results_df.link.apply(self.strip_version).isin(past_links)\n",
    "            print(f'{i}. Fetched {len(results_df)} abstracts published {max_date} and earlier')\n",
    "            if not new_links.any():\n",
    "                break\n",
    "\n",
    "            df = pd.concat((df, results_df.loc[new_links]), ignore_index=True)\n",
    "            i += 1\n",
    "            retry = 0\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "        print(f'Downloaded {len(df)-len(past_links)} new abstracts')\n",
    "        df.sort_values('published', ascending=False).groupby('link').first().reset_index()\n",
    "        df.to_pickle(self.pickle_path)\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, pickle_path):\n",
    "        \"\"\"Load data from pickle and remove duplicates\"\"\"\n",
    "        return pd.read_pickle(cls(pickle_path).pickle_path)\n",
    "\n",
    "    @classmethod\n",
    "    def update(cls, pickle_path, categories=list(), **kwargs):\n",
    "        \"\"\"\n",
    "        Update arXiv data pickle with the latest abstracts\n",
    "        \"\"\"\n",
    "        cls(pickle_path, categories).fetch_updated_data(**kwargs)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "PATH='data/arxiv/'\n",
    "\n",
    "ALL_ARXIV = f'{PATH}all_arxiv.pkl'\n",
    "\n",
    "# all_arxiv.pkl: if arxiv hasn't been downloaded yet, it'll take some time to get it - go get some coffee\n",
    "if not os.path.exists(ALL_ARXIV): GetArXiv.update(ALL_ARXIV)\n",
    "\n",
    "# arxiv.csv: see dl1/nlp-arxiv.ipynb to get this one\n",
    "df_mb = pd.read_csv(f'{PATH}arxiv.csv')\n",
    "df_all = pd.read_pickle(ALL_ARXIV)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
||||||| merged common ancestors
   "execution_count": 57,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31000"
      ]
     },
<<<<<<< HEAD
     "execution_count": 5,
||||||| merged common ancestors
     "execution_count": 57,
=======
     "execution_count": null,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_txt(df):\n",
    "    return '<CAT> ' + df.category.str.replace(r'[\\.\\-]','') + ' <SUMM> ' + df.summary + ' <TITLE> ' + df.title\n",
    "df_mb['txt'] = get_txt(df_mb)\n",
    "df_all['txt'] = get_txt(df_all)\n",
    "n=len(df_all); n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}trn/yes', exist_ok=True)\n",
    "os.makedirs(f'{PATH}val/yes', exist_ok=True)\n",
    "os.makedirs(f'{PATH}trn/no', exist_ok=True)\n",
    "os.makedirs(f'{PATH}val/no', exist_ok=True)\n",
    "os.makedirs(f'{PATH}all/trn', exist_ok=True)\n",
    "os.makedirs(f'{PATH}all/val', exist_ok=True)\n",
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "for (i,(_,r)) in enumerate(df_all.iterrows()):\n",
    "    dset = 'trn' if random.random()>0.1 else 'val'\n",
    "    open(f'{PATH}all/{dset}/{i}.txt', 'w').write(r['txt'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "for (i,(_,r)) in enumerate(df_mb.iterrows()):\n",
    "    lbl = 'yes' if r.tweeted else 'no'\n",
    "    dset = 'trn' if random.random()>0.1 else 'val'\n",
    "    open(f'{PATH}{dset}/{lbl}/{i}.txt', 'w').write(r['txt'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH\n",
    "\n",
    "# install the 'en' model if the next line of code fails by running:\n",
    "#python -m spacy download en              # default English model (~50MB)\n",
    "#python -m spacy download en_core_web_md  # larger English model (~1GB)\n",
    "my_tok = spacy.load('en')\n",
    "\n",
    "my_tok.tokenizer.add_special_case('<SUMM>', [{ORTH: '<SUMM>'}])\n",
    "my_tok.tokenizer.add_special_case('<CAT>', [{ORTH: '<CAT>'}])\n",
    "my_tok.tokenizer.add_special_case('<TITLE>', [{ORTH: '<TITLE>'}])\n",
    "my_tok.tokenizer.add_special_case('<BR />', [{ORTH: '<BR />'}])\n",
    "my_tok.tokenizer.add_special_case('<BR>', [{ORTH: '<BR>'}])\n",
    "\n",
    "def my_spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=my_spacy_tok)\n",
    "FILES = dict(train='trn', validation='val', test='val')\n",
    "md = LanguageModelData.from_text_files(f'{PATH}all/', TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)\n",
    "pickle.dump(TEXT, open(f'{PATH}models/TEXT.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
||||||| merged common ancestors
   "execution_count": 76,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1271, 14412, 1, 5699790)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 11,
||||||| merged common ancestors
     "execution_count": 76,
=======
     "execution_count": null,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
||||||| merged common ancestors
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'of', '-', 'and', 'a', 'to', 'in', 'we']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 12,
||||||| merged common ancestors
     "execution_count": 77,
=======
     "execution_count": null,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:12]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
||||||| merged common ancestors
   "execution_count": 173,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<cat> mathac <summ> in this paper we study the problem of deterministic factorization of sparse polynomials . we show that if $ f \\\\in \\\\mathbb{f}[x_{1},x_{2},\\\\ldots , x_{n}]$ is a polynomial with $ s$ monomials , with individual degrees of its variables bounded by $ d$ , then $ f$ can be deterministically factored in time $ s^{\\\\mathrm{poly}(d ) \\\\log n}$. prior to our work , the only efficient factoring algorithms known for this class of polynomials were randomized , and other than for the cases of $ d=1 $ and $ d=2 $ , only exponential time deterministic factoring algorithms were known .    a crucial ingredient in our proof is a quasi - polynomial sparsity bound for factors of sparse polynomials of bounded individual degree . in particular we show if $ f$ is an $ s$-sparse polynomial in $ n$ variables , with individual degrees of its variables'"
      ]
     },
<<<<<<< HEAD
     "execution_count": 13,
||||||| merged common ancestors
     "execution_count": 173,
=======
     "execution_count": null,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(md.trn_ds[0].text[:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "em_sz = 200\n",
    "nh = 500\n",
    "nl = 3\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "    dropout=0.05, dropouth=0.1, dropouti=0.05, dropoute=0.02, wdrop=0.2)\n",
    "# dropout=0.4, dropouth=0.3, dropouti=0.65, dropoute=0.1, wdrop=0.5\n",
    "#                dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339ea7c11d2c45ceb726feb8bb3313e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      4.621735   4.502018  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([4.50202])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa945c580794f8b9cb5e134d8b40683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      4.369812   4.278798  \n",
      "    1      4.290543   4.169997                                \n",
      "    2      4.159827   4.094938                                \n",
      "    3      4.194054   4.091485                                \n",
      "    4      4.098588   4.012515                                \n",
      "    5      4.02392    3.963573                                \n",
      "    6      3.982089   3.947681                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.94768])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 3, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "learner.save_encoder('adam2_enc')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
||||||| merged common ancestors
   "execution_count": 84,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ef07a95d484ef6bbae618bce4b7a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      4.093926   4.003164  \n",
      "    1      4.039814   3.960781                                \n",
      "    2      3.973589   3.917064                                \n",
      "    3      3.890041   3.886201                                \n",
      "    4      3.871082   3.880378                                \n",
      "    5      4.020988   3.946259                                \n",
      "    6      3.959853   3.908145                                \n",
      "    7      3.891331   3.873749                                \n",
      "    8      3.830333   3.849011                                \n",
      "    9      3.855924   3.843783                                \n",
      "    10     3.979082   3.915358                                \n",
      "    11     3.91581    3.881344                                \n",
      "    12     3.858311   3.848436                                \n",
      "    13     3.796537   3.826019                                \n",
      "    14     3.763215   3.822233                                \n",
      "    15     3.94726    3.889586                                \n",
      "    16     3.897026   3.863184                                \n",
      "    17     3.821032   3.833463                                \n",
      "    18     3.772162   3.812277                                \n",
      "    19     3.748839   3.808036                                \n",
      "    20     3.92207    3.877613                                \n",
      "    21     3.889232   3.854099                                \n",
      "    22     3.81113    3.819111                                \n",
      "    23     3.807987   3.799706                                \n",
      "    24     3.71714    3.795123                                \n",
      "    25     3.902458   3.860915                                \n",
      "    26     3.851082   3.836417                                \n",
      "    27     3.787652   3.810425                                \n",
      "    28     3.729839   3.790851                                \n",
      "    29     3.752668   3.787147                                \n",
      "    30     3.91396    3.857823                                \n",
      "    31     3.839605   3.828842                                \n",
      "    32     3.77885    3.802055                                \n",
      "    33     3.72671    3.782925                                \n",
      "    34     3.698041   3.780695                                \n",
      "    35     3.877368   3.844475                                \n",
      "    36     3.838188   3.826508                                \n",
      "    37     3.767455   3.795431                                \n",
      "    38     3.71216    3.77725                                 \n",
      "    39     3.673297   3.774464                                \n",
      "    40     3.871332   3.837957                                \n",
      "    41     3.818739   3.817312                                \n",
      "    42     3.755306   3.791418                                \n",
      "    43     3.717039   3.771777                                \n",
      "    44     3.699478   3.771021                                \n",
      "    45     3.884389   3.834957                                \n",
      "    46     3.817887   3.810186                                \n",
      "    47     3.758571   3.7853                                  \n",
      "    48     3.702194   3.766456                                \n",
      "    49     3.657401   3.765417                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.76542])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 10, wds=1e-6, cycle_len=5, cycle_save_name='adam3_10')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "learner.save_encoder('adam3_10_enc')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
||||||| merged common ancestors
   "execution_count": 86,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6551e9fa4c9445c99b9d3b17cc81df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      3.83615    3.837903  \n",
      "    1      3.821765   3.82772                                 \n",
      "    2      3.814529   3.819188                                \n",
      "    3      3.77562    3.80498                                 \n",
      "    4      3.761399   3.792065                                \n",
      "    5      3.695456   3.776722                                \n",
      "    6      3.659784   3.766794                                \n",
      "    7      3.636959   3.758339                                \n",
      "    8      3.619205   3.755518                                \n",
      "    9      3.635139   3.756653                                \n",
      "    10     3.845109   3.827575                                \n",
      "    11     3.817047   3.823249                                \n",
      "    12     3.797017   3.813657                                \n",
      "    13     3.767858   3.797147                                \n",
      "    14     3.72644    3.783541                                \n",
      "    15     3.689898   3.770698                                \n",
      "    16     3.657516   3.759869                                \n",
      "    17     3.630505   3.753412                                \n",
      "    18     3.605447   3.749898                                \n",
      "    19     3.621122   3.75088                                 \n",
      "    20     3.83394    3.818542                                \n",
      "    21     3.816428   3.816159                                \n",
      "    22     3.778901   3.807228                                \n",
      "    23     3.780187   3.793057                                \n",
      "    24     3.728563   3.777109                                \n",
      "    25     3.673459   3.765384                                \n",
      "    26     3.672932   3.75449                                 \n",
      "    27     3.62449    3.74846                                 \n",
      "    28     3.648298   3.745068                                \n",
      "    29     3.607457   3.746117                                \n",
      "    30     3.82266    3.815214                                \n",
      "    31     3.812034   3.810877                                \n",
      "    32     3.79981    3.803823                                \n",
      "    33     3.744406   3.786541                                \n",
      "    34     3.717263   3.773267                                \n",
      "    35     3.682194   3.761229                                \n",
      "    36     3.637651   3.751206                                \n",
      "    37     3.670668   3.743785                                \n",
      "    38     3.604823   3.741448                                \n",
      "    39     3.585943   3.742351                                \n",
      "    40     3.834066   3.819259                                \n",
      "    41     3.799929   3.811851                                \n",
      "    42     3.773223   3.798482                                \n",
      "    43     3.765016   3.785967                                \n",
      "    44     3.71068    3.768586                                \n",
      "    45     3.662066   3.75607                                 \n",
      "    46     3.632478   3.747736                                \n",
      "    47     3.600629   3.742072                                \n",
      "    48     3.578527   3.739301                                \n",
      "    49     3.588626   3.739838                                \n",
      "    50     3.814807   3.807074                                \n",
      "    51     3.777864   3.80072                                 \n",
      "    52     3.815983   3.797603                                \n",
      "    53     3.729278   3.780011                                \n",
      "    54     3.698098   3.766401                                \n",
      "    55     3.677429   3.753878                                \n",
      "    56     3.630426   3.744579                                \n",
      "    57     3.59666    3.737753                                \n",
      "    58     3.576424   3.736575                                \n",
      "    59     3.571275   3.73658                                 \n",
      "    60     3.800495   3.802507                                \n",
      "    61     3.782337   3.798932                                \n",
      "    62     3.76384    3.79146                                 \n",
      "    63     3.743111   3.778847                                \n",
      "    64     3.692443   3.763554                                \n",
      "    65     3.645246   3.752251                                \n",
      "    66     3.620687   3.741876                                \n",
      "    67     3.623861   3.734441                                \n",
      "    68     3.607505   3.733046                                \n",
      "    69     3.590126   3.734129                                \n",
      "    70     3.830923   3.805677                                \n",
      "    71     3.777227   3.79441                                 \n",
      "    72     3.75173    3.788368                                \n",
      "    73     3.753399   3.78109                                 \n",
      "    74     3.70693    3.760583                                \n",
      "    75     3.641072   3.75115                                 \n",
      "    76     3.641418   3.739623                                \n",
      "    77     3.606848   3.733356                                \n",
      "    78     3.581487   3.731245                                \n",
      "    79     3.572126   3.73223                                 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.73223])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 8, wds=1e-6, cycle_len=10, cycle_save_name='adam3_5')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6fcfcc4e6a4eb0a238840a61eda42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      3.582704   3.732298  \n",
      "    1      3.789118   3.799171                                \n",
      "    2      3.775184   3.796418                                \n",
      "    3      3.767308   3.794498                                \n",
      "    4      3.751212   3.789561                                \n",
      "    5      3.773098   3.787449                                \n",
      "    6      3.750549   3.777775                                \n",
      "    7      3.708927   3.771768                                \n",
      "    8      3.678446   3.764111                                \n",
      "    9      3.695551   3.757428                                \n",
      "    10     3.644611   3.751775                                \n",
      "    11     3.621013   3.746119                                \n",
      "    12     3.619947   3.74048                                 \n",
      "    13     3.634542   3.735098                                \n",
      "    14     3.602568   3.731974                                \n",
      "    15     3.581497   3.729351                                \n",
      "    16     3.588641   3.727887                                \n",
      "    17     3.534935   3.727633                                \n",
      "    18     3.567607   3.728021                                \n",
      "    19     3.530106   3.728431                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.72843])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=20, cycle_save_name='adam3_20')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "learner.save_encoder('adam3_20_enc')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "learner.save('adam3_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "def proc_str(s): return TEXT.preprocess(TEXT.tokenize(s))\n",
    "def num_str(s): return TEXT.numericalize([proc_str(s)])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "m=learner.model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "s=\"\"\"<CAT> cscv <SUMM> algorithms that\"\"\""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "def sample_model(m, s, l=50):\n",
    "    t = num_str(s)\n",
    "    m[0].bs=1\n",
    "    m.eval()\n",
    "    m.reset()\n",
    "    res,*_ = m(t)\n",
    "    print('...', end='')\n",
    "\n",
    "    for i in range(l):\n",
    "        n=res[-1].topk(2)[1]\n",
    "        n = n[1] if n.data[0]==0 else n[0]\n",
    "        word = TEXT.vocab.itos[n.data[0]]\n",
    "        print(word, end=' ')\n",
    "        if word=='<eos>': break\n",
    "        res,*_ = m(n[0].unsqueeze(0))\n",
    "\n",
    "    m[0].bs=bs"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
||||||| merged common ancestors
   "execution_count": 218,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...are able to perform the task of video streaming are often based on the use of a single - stream network . in this paper , we propose a novel approach to the problem of video streaming . we first propose a novel algorithm to compute the optimal video streaming "
     ]
    }
   ],
   "source": [
    "sample_model(m,\"<CAT> csni <SUMM> algorithms that\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
||||||| merged common ancestors
   "execution_count": 219,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...perform image segmentation are based on the segmentation of the objects in the image . however , the segmentation of the objects is difficult due to the large number of images and the number of objects in the image . in this paper , we propose a novel method for "
     ]
    }
   ],
   "source": [
    "sample_model(m,\"<CAT> cscv <SUMM> algorithms that\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
||||||| merged common ancestors
   "execution_count": 224,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...the use of a deep learning approach for image segmentation <eos> "
     ]
    }
   ],
   "source": [
    "sample_model(m,\"<CAT> cscv <SUMM> algorithms. <TITLE> on \")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
||||||| merged common ancestors
   "execution_count": 225,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...the performance of a multi - hop wireless network <eos> "
     ]
    }
   ],
   "source": [
    "sample_model(m,\"<CAT> csni <SUMM> algorithms. <TITLE> on \")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
||||||| merged common ancestors
   "execution_count": 226,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...a new approach for image segmentation <eos> "
     ]
    }
   ],
   "source": [
    "sample_model(m,\"<CAT> cscv <SUMM> algorithms. <TITLE> towards \")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
||||||| merged common ancestors
   "execution_count": 227,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...a new framework for the design of a network of mobile devices <eos> "
     ]
    }
   ],
   "source": [
    "sample_model(m,\"<CAT> csni <SUMM> algorithms. <TITLE> towards \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "TEXT = pickle.load(open(f'{PATH}models/TEXT.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "class ArxivDataset(torchtext.data.Dataset):\n",
    "    def __init__(self, path, text_field, label_field, **kwargs):\n",
    "        fields = [('text', text_field), ('label', label_field)]\n",
    "        examples = []\n",
    "        for label in ['yes', 'no']:\n",
    "            fnames = glob(os.path.join(path, label, '*.txt'));\n",
    "            assert fnames, f\"can't find 'yes.txt' or 'no.txt' under {path}/{label}\"\n",
    "            for fname in fnames:\n",
    "                with open(fname, 'r') as f: text = f.readline()\n",
    "                examples.append(data.Example.fromlist([text, label], fields))\n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex): return len(ex.text)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, text_field, label_field, root='.data',\n",
    "               train='train', test='test', **kwargs):\n",
    "        return super().splits(\n",
    "            root, text_field=text_field, label_field=label_field,\n",
    "            train=train, validation=None, test=test, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "ARX_LABEL = data.Field(sequential=False)\n",
    "splits = ArxivDataset.splits(TEXT, ARX_LABEL, PATH, train='trn', test='val')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "md2 = TextData.from_splits(PATH, splits, bs)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "#            dropout=0.3, dropouti=0.4, wdrop=0.3, dropoute=0.05, dropouth=0.2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def prec_at_6(preds,targs):\n",
    "    precision, recall, _ = precision_recall_curve(targs==2, preds[:,2])\n",
    "    print(recall[precision>=0.6][0])\n",
    "    return recall[precision>=0.6][0]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "# dropout=0.4, dropouth=0.3, dropouti=0.65, dropoute=0.1, wdrop=0.5\n",
    "m3 = md2.get_model(opt_fn, 1500, bptt, emb_sz=em_sz, n_hid=nh, n_layers=nl, \n",
    "           dropout=0.1, dropouti=0.65, wdrop=0.5, dropoute=0.1, dropouth=0.3)\n",
    "m3.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "m3.clip=25."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
   "metadata": {},
||||||| merged common ancestors
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "# this notebook has a mess of some things going under 'all/' others not, so a little hack here\n",
    "!ln -sf ../all/models/adam3_20_enc.h5 {PATH}models/adam3_20_enc.h5\n",
    "m3.load_encoder(f'adam3_20_enc')\n",
    "lrs=np.array([1e-4,1e-3,1e-3,1e-2,3e-2])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
||||||| merged common ancestors
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
=======
   "execution_count": null,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da9c614790342d584bf1fa56f9fa5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.497768   0.391132   0.816671  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe9ac6adc434b4d9e088c8a83b2140d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.450256   0.428212   0.789924  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.42821]), 0.7899240451943443]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.freeze_to(-1)\n",
    "m3.fit(lrs/2, 1, metrics=[accuracy])\n",
    "m3.unfreeze()\n",
    "m3.fit(lrs, 1, metrics=[accuracy], cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
||||||| merged common ancestors
   "execution_count": 159,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf4e6c1630e40ec818dc1260dc729de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.473896   0.456998   0.790301  \n",
      "    1      0.436972   0.561504   0.744487                    \n",
      "    2      0.428872   0.388516   0.816059                    \n",
      "    3      0.428562   0.388136   0.797807                    \n",
      "    4      0.443999   0.415152   0.800105                    \n",
      "    5      0.42642    0.458471   0.780585                    \n",
      "    6      0.411019   0.424532   0.825892                    \n",
      "    7      0.406126   0.399067   0.825469                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.39907]), 0.8254688080534878]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(lrs, 2, metrics=[accuracy], cycle_len=4, cycle_save_name='imdb2')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
||||||| merged common ancestors
   "execution_count": 160,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4400715563506261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4400715563506261"
      ]
     },
<<<<<<< HEAD
     "execution_count": 45,
||||||| merged common ancestors
     "execution_count": 160,
=======
     "execution_count": null,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec_at_6(*m3.predict_with_targs())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
||||||| merged common ancestors
   "execution_count": 161,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbed3f57e45e4b1083833add7bc2668e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.418076   0.532346   0.777808  \n",
      "    1      0.397858   0.380552   0.825616                    \n",
      "    2      0.423545   0.399825   0.814788                    \n",
      "    3      0.394082   0.39749    0.826036                    \n",
      "    4      0.40693    0.401446   0.831496                    \n",
      "    5      0.392895   0.396877   0.835355                    \n",
      "    6      0.410037   0.41516    0.829443                    \n",
      "    7      0.39106    0.453009   0.823377                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.45301]), 0.82337737514312]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(lrs, 4, metrics=[accuracy], cycle_len=2, cycle_save_name='imdb2')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 47,
||||||| merged common ancestors
   "execution_count": 162,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
<<<<<<< HEAD
     "execution_count": 47,
||||||| merged common ancestors
     "execution_count": 162,
=======
     "execution_count": null,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec_at_6(*m3.predict_with_targs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
<<<<<<< HEAD
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
||||||| merged common ancestors
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
=======
>>>>>>> upstream/master
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
