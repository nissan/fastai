{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as Pickle\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [large movie view dataset](http://ai.stanford.edu/~amaas/data/sentiment/) contains a collection of 50,000 reviews from IMDB. The dataset contains an even number of positive and negative reviews. The authors considered only highly polarized reviews. A negative review has a score ≤ 4 out of 10, and a positive review has a score ≥ 7 out of 10. Neutral reviews are not included in the dataset. The dataset is divided into training and test sets. The training set is the same 25,000 labeled reviews.\n",
    "\n",
    "The **sentiment classification task** consists of predicting the polarity (positive or negative) of a given text.\n",
    "\n",
    "However, before we try to classify *sentiment*, we will simply try to create a *language model*; that is, a model that can predict the next word in a sentence. Why? Because our model first needs to understand the structure of English, before we can expect it to recognize positive vs negative sentiment.\n",
    "\n",
    "So our plan of attack is the same as we used for Dogs v Cats: pretrain a model to do one thing (predict the next word), and fine tune it to do something else (classify sentiment).\n",
    "\n",
    "Unfortunately, there are no good pretrained language models available to download, so we need to create our own. To follow along with this notebook, we suggest downloading the dataset from [this location](http://files.fast.ai/data/aclImdb.tgz) on files.fast.ai.\n",
    "\n",
    "I have also added a top articles from Wikipedia dump file from [this location](http://www.evanjones.ca/software/wikipedia2text.html) specifically the item listed as \n",
    "**Extracted plain text: wikipedia2text-extracted.txt.bz2 (18 MB compressed; 63 MB uncompressed; 10 million words)**\n",
    "\n",
    "The hope is adding 10 million more words can tune a more generalized PKL file for use in other NLP problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README\n",
      "imdb.vocab\n",
      "imdbEr.txt\n",
      "models\n",
      "test\n",
      "tmp\n",
      "train\n"
     ]
    }
   ],
   "source": [
    "PATH='data/aclImdb'\n",
    "\n",
    "TRN_PATH = 'train/all'\n",
    "VAL_PATH = 'test/all'\n",
    "TRN = f'{PATH}/{TRN_PATH}'\n",
    "VAL = f'{PATH}/{VAL_PATH}'\n",
    "\n",
    "# %ls {PATH}\n",
    "!C:/ProgramData/chocolatey/bin/ls {PATH}\n",
    "    # {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look inside the training folder..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_0.txt',\n",
       " '0_3.txt',\n",
       " '0_9.txt',\n",
       " '10000_0.txt',\n",
       " '10000_4.txt',\n",
       " '10000_8.txt',\n",
       " '10001_0.txt',\n",
       " '10001_10.txt',\n",
       " '10001_4.txt',\n",
       " '10002_0.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_files = !ls {TRN}\n",
    "trn_files[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and at an example review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Everybody has seen 'Back To The Future,' right? Whether you LIKE that movie or not, you've seen an example of how to make a time-travel movie work. A torn-up poster for 'Back To The Future' shows up in this movie, representing, perhaps unintentionally, what the makers of 'Tangents' (aka 'Time Chasers') did to the time-travel formula. Then again, the movie claims to have been made in 1994, but it looks -- and sounds -- like it was produced at least ten years earlier, so maybe they achieved time-travel after all.<br /><br />Start with an intensely unappealing leading man. I mean, what woman doesn't love gangly, whiny, lantern-jawed, butt-chinned, mullet-men with Coke-bottle glasses? Oh, none of you? Prepare to tough it out, ladies, cuz that's what this movie gives you.<br /><br />Second, add a leading lady who -- while not entirely unattractive -- represents many '80s clichÃ©s: big hair, too much makeup, two different plaids, shoulder pads, acid-washed mom-jeans, etc.<br /><br />Throw in a Michael Medved look-alike who wears pink blazers with white pants, a stunningly transparent villain who talks like Mortimer Snerd and has an office that looks like a circus-themed library, and evil henchmen who have nothing better to do than direct air traffic. That's our cast, folks. Enjoy!<br /><br />I could try to explain the plot, but it will take a lot less time for you to just track down a copy of this movie and watch it yourself. If YOU figure out the plot, please don't hesitate to share it with me.<br /><br />I would strongly advise watching this movie with the help of the folks at Mystery Science Theater 3000. I don't think it could stand on its own.<br /><br />The film, 'Tangents': 3 stars -- at least they tried.<br /><br />MST3K's 'Time Chasers' episode: 8 stars -- they actually succeeded.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = !cat {TRN}/{trn_files[6]}\n",
    "review[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can analyze text, we must first *tokenize* it. This refers to the process of splitting a sentence into an array of words (or more generally, into an array of *tokens*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* If you get an error like:\n",
    "\n",
    "    Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.\n",
    "    \n",
    "then you need to install the Spacy language model by running this command on the command-line:\n",
    "\n",
    "    $ python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tok = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Everybody has seen ' Back To The Future , ' right ? Whether you LIKE that movie or not , you 've seen an example of how to make a time - travel movie work . A torn - up poster for ' Back To The Future ' shows up in this movie , representing , perhaps unintentionally , what the makers of ' Tangents ' ( aka ' Time Chasers ' ) did to the time - travel formula . Then again , the movie claims to have been made in 1994 , but it looks -- and sounds -- like it was produced at least ten years earlier , so maybe they achieved time - travel after all.<br /><br />Start with an intensely unappealing leading man . I mean , what woman does n't love gangly , whiny , lantern - jawed , butt - chinned , mullet - men with Coke - bottle glasses ? Oh , none of you ? Prepare to tough it out , ladies , cuz that 's what this movie gives you.<br /><br />Second , add a leading lady who -- while not entirely unattractive -- represents many ' 80s clichÃ © s : big hair , too much makeup , two different plaids , shoulder pads , acid - washed mom - jeans , etc.<br /><br />Throw in a Michael Medved look - alike who wears pink blazers with white pants , a stunningly transparent villain who talks like Mortimer Snerd and has an office that looks like a circus - themed library , and evil henchmen who have nothing better to do than direct air traffic . That 's our cast , folks . Enjoy!<br /><br />I could try to explain the plot , but it will take a lot less time for you to just track down a copy of this movie and watch it yourself . If YOU figure out the plot , please do n't hesitate to share it with me.<br /><br />I would strongly advise watching this movie with the help of the folks at Mystery Science Theater 3000 . I do n't think it could stand on its own.<br /><br />The film , ' Tangents ' : 3 stars -- at least they tried.<br /><br />MST3 K 's ' Time Chasers ' episode : 8 stars -- they actually succeeded .\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([sent.string.strip() for sent in spacy_tok(review[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Pytorch's [torchtext](https://github.com/pytorch/text) library to preprocess our data, telling it to use the wonderful [spacy](https://spacy.io/) library to handle tokenization.\n",
    "\n",
    "First, we create a torchtext *field*, which describes how to preprocess a piece of text - in this case, we tell torchtext to make everything lowercase, and tokenize it with spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=\"spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai works closely with torchtext. We create a ModelData object for language modeling by taking advantage of `LanguageModelData`, passing it our torchtext field object, and the paths to our training, test, and validation sets. In this case, we don't have a separate test set, so we'll just use `VAL_PATH` for that too.\n",
    "\n",
    "As well as the usual `bs` (batch size) parameter, we also now have `bptt`; this define how many words are processing at a time in each row of the mini-batch. More importantly, it defines how many 'layers' we will backprop through. Making this number higher will increase time and memory requirements, but will improve the model's ability to handle long sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=16; bptt=35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building our `ModelData` object, it automatically fills the `TEXT` object with a very important attribute: `TEXT.vocab`. This is a *vocabulary*, which stores which words (or *tokens*) have been seen in the text, and how each word will be mapped to a unique integer id. We'll need to use this information again later, so we save it.\n",
    "\n",
    "*(Technical note: python's standard `Pickle` library can't handle this correctly, so at the top of this notebook we used the `dill` library instead and imported it as `pickle`)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pickle.dump(TEXT, open(f'{PATH}/models/TEXTLOCALIMDBWIKIPEDIA.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the: # batches; # unique tokens in the vocab; # tokens in the training set; # sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57838, 56823, 1, 32389949)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the start of the mapping from integer IDs to unique tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'of', 'and', 'a', 'to', 'in', 'is', 'it']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'itos': 'int-to-string'\n",
    "TEXT.vocab.itos[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'stoi': 'string to int'\n",
    "TEXT.vocab.stoi['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in a `LanguageModelData` object there is only one item in each dataset: all the words of the text joined together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'admit',\n",
       " ',',\n",
       " 'the',\n",
       " 'great',\n",
       " 'majority',\n",
       " 'of',\n",
       " 'films',\n",
       " 'released',\n",
       " 'before',\n",
       " 'say',\n",
       " '1933']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.trn_ds[0].text[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchtext will handle turning this words into integer IDs for us automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   17\n",
       " 1570\n",
       "    3\n",
       "    2\n",
       "  107\n",
       "  994\n",
       "    5\n",
       "  140\n",
       "  576\n",
       "  160\n",
       "  179\n",
       " 5092\n",
       "[torch.cuda.LongTensor of size 12x1 (GPU 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.numericalize([md.trn_ds[0].text[:12]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `LanguageModelData` object will create batches with 64 columns (that's our batch size), and varying sequence lengths of around 80 tokens (that's our `bptt` parameter - *backprop through time*).\n",
    "\n",
    "Each batch also contains the exact same data as labels, but one word later in the text - since we're trying to always predict the next word. The labels are flattened into a 1d array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " \n",
       " Columns 0 to 10 \n",
       "     17     19   9528   3230     98      4      4      2      0     17   3823\n",
       "   1570     40    580     75    349     44   1125   1583     10   3978    154\n",
       "      3      5      4   1024      3     43      3     49      7    158      3\n",
       "      2      2      0     52     82     93  14438     88     97     46     62\n",
       "    107    182   5090  26867     42     18      3    288   1651     93    183\n",
       "    994    156     36     13    118    256  14438      3     32     33     36\n",
       "      5    967    210     11      3      7    199     11      3    543      7\n",
       "    140    355      8     10     13     40      3     15     20     11    124\n",
       "    576      8    210    314     31    761   1897     62      7      3      4\n",
       "    160    969      4     33     69    186      3     13    186     17     26\n",
       "    179     21      9      8   4247   1335   8544      2     70     64      2\n",
       "   5092      2   6923   5720    426     20      3     32     11   1459   3392\n",
       "     28    544    121      4     60    239    841     45   8329     21      5\n",
       "     62    266      2     81      5    307     16     77     74     55   3823\n",
       "     33     15     30      5      4      4   8544   1546      8      5   1212\n",
       "     20   9605     10     11     71     28      3     37     34      2   1667\n",
       "    108   2839    301     10     96     43    709     44      7   9160   6841\n",
       "      4     20    436     62    246   6305      4      4   5464      4     20\n",
       "      5   4803      0    694    996     13    141    212    142     48    313\n",
       "      2      4     10   5112      9    239      5      4    264      3     84\n",
       "   3342    156     40    144     29    307   3229      2   1110      9     11\n",
       "     42    454  13452     36    122     45     21    302   1093      7    282\n",
       "     52      7      4   1547      4    104    402     18     26    982      9\n",
       "     12   2374     52     16     80      7      9   2762     11    122      7\n",
       "    296   1898  49088   5453     28    868      2      8    135      3    125\n",
       "     12     83   7329   1094      2    458    697    341   3348    198     52\n",
       "  21805     79     71      4  19779     83      4     11    320    108   8948\n",
       " \n",
       " Columns 11 to 15 \n",
       "     31   2391      3      9   5090\n",
       "    642   3183    123    560      9\n",
       "    109      8      9      3      2\n",
       "     60  11247      2    280    945\n",
       "      9   1823   1599     14    436\n",
       "     52      4      6     11     16\n",
       "     91    907     98    138   2499\n",
       "    678   7549      5     34    452\n",
       "     54   3605      2   2385      3\n",
       "      2  17555   2868     13     21\n",
       "    438      8      2      3      7\n",
       "     46     40    743    176    516\n",
       "    219  16044  17780      2      5\n",
       "     37      6   5952   1727  51615\n",
       "      2   1176   7320      5      4\n",
       "    615  14092      6  18799    194\n",
       "    229    833     10     10     14\n",
       "   8473      0  16909   1286     67\n",
       "      2      4     27   1337   2344\n",
       "   3783      9      2    955      2\n",
       "     19   3625   1954      3   5458\n",
       "     43      3      0   1060      5\n",
       "    543   2131      4      2      2\n",
       "    109      9      9  14328   2641\n",
       "      4      2     81      5      8\n",
       "   1516  13732    455     39     91\n",
       "  46576      6    682   6445     92\n",
       " [torch.cuda.LongTensor of size 27x16 (GPU 0)], Variable containing:\n",
       "   1570\n",
       "     40\n",
       "    580\n",
       "     75\n",
       "    349\n",
       "     44\n",
       "   1125\n",
       "   1583\n",
       "     10\n",
       "   3978\n",
       "    154\n",
       "    642\n",
       "   3183\n",
       "    123\n",
       "    560\n",
       "      9\n",
       "      3\n",
       "      5\n",
       "      4\n",
       "   1024\n",
       "      3\n",
       "     43\n",
       "      3\n",
       "     49\n",
       "      7\n",
       "    158\n",
       "      3\n",
       "    109\n",
       "      8\n",
       "      9\n",
       "      3\n",
       "      2\n",
       "      2\n",
       "      2\n",
       "      0\n",
       "     52\n",
       "     82\n",
       "     93\n",
       "  14438\n",
       "     88\n",
       "     97\n",
       "     46\n",
       "     62\n",
       "     60\n",
       "  11247\n",
       "      2\n",
       "    280\n",
       "    945\n",
       "    107\n",
       "    182\n",
       "   5090\n",
       "  26867\n",
       "     42\n",
       "     18\n",
       "      3\n",
       "    288\n",
       "   1651\n",
       "     93\n",
       "    183\n",
       "      9\n",
       "   1823\n",
       "   1599\n",
       "     14\n",
       "    436\n",
       "    994\n",
       "    156\n",
       "     36\n",
       "     13\n",
       "    118\n",
       "    256\n",
       "  14438\n",
       "      3\n",
       "     32\n",
       "     33\n",
       "     36\n",
       "     52\n",
       "      4\n",
       "      6\n",
       "     11\n",
       "     16\n",
       "      5\n",
       "    967\n",
       "    210\n",
       "     11\n",
       "      3\n",
       "      7\n",
       "    199\n",
       "     11\n",
       "      3\n",
       "    543\n",
       "      7\n",
       "     91\n",
       "    907\n",
       "     98\n",
       "    138\n",
       "   2499\n",
       "    140\n",
       "    355\n",
       "      8\n",
       "     10\n",
       "     13\n",
       "     40\n",
       "      3\n",
       "     15\n",
       "     20\n",
       "     11\n",
       "    124\n",
       "    678\n",
       "   7549\n",
       "      5\n",
       "     34\n",
       "    452\n",
       "    576\n",
       "      8\n",
       "    210\n",
       "    314\n",
       "     31\n",
       "    761\n",
       "   1897\n",
       "     62\n",
       "      7\n",
       "      3\n",
       "      4\n",
       "     54\n",
       "   3605\n",
       "      2\n",
       "   2385\n",
       "      3\n",
       "    160\n",
       "    969\n",
       "      4\n",
       "     33\n",
       "     69\n",
       "    186\n",
       "      3\n",
       "     13\n",
       "    186\n",
       "     17\n",
       "     26\n",
       "      2\n",
       "  17555\n",
       "   2868\n",
       "     13\n",
       "     21\n",
       "    179\n",
       "     21\n",
       "      9\n",
       "      8\n",
       "   4247\n",
       "   1335\n",
       "   8544\n",
       "      2\n",
       "     70\n",
       "     64\n",
       "      2\n",
       "    438\n",
       "      8\n",
       "      2\n",
       "      3\n",
       "      7\n",
       "   5092\n",
       "      2\n",
       "   6923\n",
       "   5720\n",
       "    426\n",
       "     20\n",
       "      3\n",
       "     32\n",
       "     11\n",
       "   1459\n",
       "   3392\n",
       "     46\n",
       "     40\n",
       "    743\n",
       "    176\n",
       "    516\n",
       "     28\n",
       "    544\n",
       "    121\n",
       "      4\n",
       "     60\n",
       "    239\n",
       "    841\n",
       "     45\n",
       "   8329\n",
       "     21\n",
       "      5\n",
       "    219\n",
       "  16044\n",
       "  17780\n",
       "      2\n",
       "      5\n",
       "     62\n",
       "    266\n",
       "      2\n",
       "     81\n",
       "      5\n",
       "    307\n",
       "     16\n",
       "     77\n",
       "     74\n",
       "     55\n",
       "   3823\n",
       "     37\n",
       "      6\n",
       "   5952\n",
       "   1727\n",
       "  51615\n",
       "     33\n",
       "     15\n",
       "     30\n",
       "      5\n",
       "      4\n",
       "      4\n",
       "   8544\n",
       "   1546\n",
       "      8\n",
       "      5\n",
       "   1212\n",
       "      2\n",
       "   1176\n",
       "   7320\n",
       "      5\n",
       "      4\n",
       "     20\n",
       "   9605\n",
       "     10\n",
       "     11\n",
       "     71\n",
       "     28\n",
       "      3\n",
       "     37\n",
       "     34\n",
       "      2\n",
       "   1667\n",
       "    615\n",
       "  14092\n",
       "      6\n",
       "  18799\n",
       "    194\n",
       "    108\n",
       "   2839\n",
       "    301\n",
       "     10\n",
       "     96\n",
       "     43\n",
       "    709\n",
       "     44\n",
       "      7\n",
       "   9160\n",
       "   6841\n",
       "    229\n",
       "    833\n",
       "     10\n",
       "     10\n",
       "     14\n",
       "      4\n",
       "     20\n",
       "    436\n",
       "     62\n",
       "    246\n",
       "   6305\n",
       "      4\n",
       "      4\n",
       "   5464\n",
       "      4\n",
       "     20\n",
       "   8473\n",
       "      0\n",
       "  16909\n",
       "   1286\n",
       "     67\n",
       "      5\n",
       "   4803\n",
       "      0\n",
       "    694\n",
       "    996\n",
       "     13\n",
       "    141\n",
       "    212\n",
       "    142\n",
       "     48\n",
       "    313\n",
       "      2\n",
       "      4\n",
       "     27\n",
       "   1337\n",
       "   2344\n",
       "      2\n",
       "      4\n",
       "     10\n",
       "   5112\n",
       "      9\n",
       "    239\n",
       "      5\n",
       "      4\n",
       "    264\n",
       "      3\n",
       "     84\n",
       "   3783\n",
       "      9\n",
       "      2\n",
       "    955\n",
       "      2\n",
       "   3342\n",
       "    156\n",
       "     40\n",
       "    144\n",
       "     29\n",
       "    307\n",
       "   3229\n",
       "      2\n",
       "   1110\n",
       "      9\n",
       "     11\n",
       "     19\n",
       "   3625\n",
       "   1954\n",
       "      3\n",
       "   5458\n",
       "     42\n",
       "    454\n",
       "  13452\n",
       "     36\n",
       "    122\n",
       "     45\n",
       "     21\n",
       "    302\n",
       "   1093\n",
       "      7\n",
       "    282\n",
       "     43\n",
       "      3\n",
       "      0\n",
       "   1060\n",
       "      5\n",
       "     52\n",
       "      7\n",
       "      4\n",
       "   1547\n",
       "      4\n",
       "    104\n",
       "    402\n",
       "     18\n",
       "     26\n",
       "    982\n",
       "      9\n",
       "    543\n",
       "   2131\n",
       "      4\n",
       "      2\n",
       "      2\n",
       "     12\n",
       "   2374\n",
       "     52\n",
       "     16\n",
       "     80\n",
       "      7\n",
       "      9\n",
       "   2762\n",
       "     11\n",
       "    122\n",
       "      7\n",
       "    109\n",
       "      9\n",
       "      9\n",
       "  14328\n",
       "   2641\n",
       "    296\n",
       "   1898\n",
       "  49088\n",
       "   5453\n",
       "     28\n",
       "    868\n",
       "      2\n",
       "      8\n",
       "    135\n",
       "      3\n",
       "    125\n",
       "      4\n",
       "      2\n",
       "     81\n",
       "      5\n",
       "      8\n",
       "     12\n",
       "     83\n",
       "   7329\n",
       "   1094\n",
       "      2\n",
       "    458\n",
       "    697\n",
       "    341\n",
       "   3348\n",
       "    198\n",
       "     52\n",
       "   1516\n",
       "  13732\n",
       "    455\n",
       "     39\n",
       "     91\n",
       "  21805\n",
       "     79\n",
       "     71\n",
       "      4\n",
       "  19779\n",
       "     83\n",
       "      4\n",
       "     11\n",
       "    320\n",
       "    108\n",
       "   8948\n",
       "  46576\n",
       "      6\n",
       "    682\n",
       "   6445\n",
       "     92\n",
       "     17\n",
       "     11\n",
       "  16766\n",
       "      2\n",
       "      3\n",
       "    793\n",
       "     47\n",
       "  12635\n",
       "     48\n",
       "     53\n",
       "   1735\n",
       "   6742\n",
       "      2\n",
       "      3\n",
       "   2225\n",
       "      3\n",
       " [torch.cuda.LongTensor of size 432 (GPU 0)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a number of parameters to set - we'll learn more about these later, but you should find these values suitable for many problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 200  # size of each embedding vector\n",
    "nh = 500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Researchers have found that large amounts of *momentum* (which we'll learn about later) don't work well with these kinds of *RNN* models, so we create a version of the *Adam* optimizer with less momentum than it's default of `0.9`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai uses a variant of the state of the art [AWD LSTM Language Model](https://arxiv.org/abs/1708.02182) developed by Stephen Merity. A key feature of this model is that it provides excellent regularization through [Dropout](https://en.wikipedia.org/wiki/Convolutional_neural_network#Dropout). There is no simple way known (yet!) to find the best values of the dropout parameters below - you just have to experiment...\n",
    "\n",
    "However, the other parameters (`alpha`, `beta`, and `clip`) shouldn't generally need tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see below, I gradually tuned the language model in a few stages. I possibly could have trained it further (it wasn't yet overfitting), but I didn't have time to experiment more. Maybe you can see if you can train it to a better accuracy! (I used `lr_find` to find a good learning rate, but didn't save the output in this notebook. Feel free to try running it yourself now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0dbe8004324038950113b131da79a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                                                         \n",
      "    0      5.089685   4.708887  \n",
      "    1      5.078059   4.733121                                                                                         \n",
      " 27%|█████████████████▌                                                | 15353/57838 [27:36<1:16:24,  9.27it/s, loss=5]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e0cb669c6e7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle_mult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[1;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\model.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, xs, y, epoch)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mupdate_fp32_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m---> 99\u001b[1;33m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.fit(1e-3, 3, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('adam1_local_wenc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_encoder('adam1_local_wenc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sentiment analysis section, we'll just need half of the language model - the *encoder*, so we save that part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('adam3_local_w10_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_encoder('adam3_local_w10_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language modeling accuracy is generally measured using the metric *perplexity*, which is simply `exp()` of the loss function we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('adam3_local_w20_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_encoder('adam3_local_w20_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('adam3_local_w35_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(4.165)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can play around with our language model a bit to check it seems to be working OK. First, let's create a short bit of text to 'prime' a set of predictions. We'll use our torchtext field to numericalize it so we can feed it to our language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m=learner.model\n",
    "ss=\"\"\". So, it wasn't quite was I was expecting, but I really liked it anyway! The best\"\"\"\n",
    "s = [TEXT.preprocess(ss)]\n",
    "t=TEXT.numericalize(s)\n",
    "' '.join(s[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We haven't yet added methods to make it easy to test a language model, so we'll need to manually go through the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set batch size to 1\n",
    "m[0].bs=1\n",
    "# Turn off dropout\n",
    "m.eval()\n",
    "# Reset hidden state\n",
    "m.reset()\n",
    "# Get predictions from model\n",
    "res,*_ = m(t)\n",
    "# Put the batch size back to what it was\n",
    "m[0].bs=bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's see what the top 10 predictions were for the next word after our short text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nexts = torch.topk(res[-1], 10)[1]\n",
    "[TEXT.vocab.itos[o] for o in to_np(nexts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "...and let's see if our model can generate a bit more text all by itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(ss,\"\\n\")\n",
    "for i in range(50):\n",
    "    n=res[-1].topk(2)[1]\n",
    "    n = n[1] if n.data[0]==0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to save the vocab from the language model as well as the encodings, since we need to ensure the same words map to the same IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
